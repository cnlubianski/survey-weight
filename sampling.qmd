---
title: "Sampling"
format: html
editor: visual
---

# Sampling CE

```{r, message = FALSE, warning = FALSE}
if (!require(tidyverse)) install.packages("tidyverse"); library(tidyverse)
if (!require(rpms)) install.packages("rpms"); library(rpms)
if (!require(sampling)) install.packages("sampling"); library(sampling)
if (!require(survey)) install.packages("survey"); library(survey)
```

## Filtering & EDA

First, we need to get to our population to sample from by filtering and doing a small exploratory data analysis to justify our selection.

```{r}
ce = rpms::CE %>%
  filter(SALARYX < 250000 & SALARYX > 0) %>%
  filter(TOTEXPCQ > 0 & FINCBTAX > 10 & !is.na(REGION) & !is.na(STATE)) %>%
  mutate(TOTEXPCQ = log(TOTEXPCQ), FINCBTAX = log(FINCBTAX)) %>%
  select(-c(QINTRVMO, PSU, INCNONWK, IRAX, LIQUIDX, STOCKX, STUDNTX,
            FOOTWRCQ, TOBACCCQ, TOTXEST, VEHQL))

ce = ce %>%
  group_by(CID) %>%
  filter(n() >= 50) %>%
  ungroup() %>%
  mutate(CID = droplevels(CID))

ce = ce %>%
  group_by(STATE) %>%
  filter(n() >= 50) %>%
  ungroup() %>%
  mutate(STATE = droplevels(STATE))

ce = ce %>%
  group_by(STATE, POPSIZE) %>%
  filter(n() >= 50) %>%
  ungroup()
  


ggplot(ce, aes(x = TOTEXPCQ, y = FINCBTAX)) + 
  geom_point(alpha = 0.05, aes(size = FINLWT21)) + 
  geom_smooth(method = "lm", color = "blue") + 
  geom_smooth(method = "lm", aes(weight = FINLWT21), color = "green")
```

## Sampling

### Grouping

```{r}
grouping <- function(x, n, strata_prob) {
  N_h = length(nh) # Number of stratum
  quantiles <- quantile(x, probs = seq(0, 1, 1 / N_h), na.rm = TRUE)
  groups <- cut(x, breaks = quantiles, labels = FALSE, include.lowest = TRUE)
  pik = inclusionprobastrata(strata = groups,
                           nh = ceiling(sample_size * strata_prob))
  selected = UPbrewer(pik)
  return(list(pik = pik, sample = selected))
}

sample_size = 100
strata_prob = c(0.1, 0.15, 0.25, 0.5)

hi = grouping(x = ce$FINCBTAX, n = sample_size, strata_prob = strata_prob)
```

### Probability Proportional to Size (PPS)

With sampling with the inclusion probabilities proportional to size (PPS), an element of randomness is added to the sampling to account for some variability. Since PPS is positive-definite, it is problematic to suggest an additive random noise process $Z_i = Y_i + \varepsilon_i, \forall i$ where $Z_i$ is the observed response variable, $Y_i$ is the signal derived from the dataset, and $\varepsilon$ is the noise term. Without imposing arbitrary distributional characteristics to $\varepsilon$ to ensure $Z_i > 0$ for all $i$, we should consider a multiplicative regression $$Z_i = Y_i * (1 + \varepsilon_i).$$ Let $\varepsilon \overset{iid}{\sim} \mathcal{N}(0, \sigma^2)$. Then $$E(Z) = E(Y * (1 + \varepsilon)) = E(Y + Y \varepsilon) = E(Y) + E(Y \varepsilon) = E(Y) = Y, \text{ by } Y \perp\!\!\!\!\perp \varepsilon.$$

```{=tex}
\begin{align*}
  \text{Var}(Z) &= \text{Var}(Y * (1 + \varepsilon)) \\ 
  &= \text{Var}(Y) + \text{Var}(Y \varepsilon) + 2 \text{Cov}(Y, Y \varepsilon).
\end{align*}
```
```{=tex}
\begin{equation*}
  \text{Cov}(Y, Y \varepsilon) = E(Y^2 \varepsilon) - E(Y)^2 E(\varepsilon) = E(Y^2) E(\varepsilon) = 0
\end{equation*}
```
```{=tex}
\begin{align*}
  \text{Var}(Y \epsilon) &= \text{Var}(E(Y \varepsilon \mid Y)) + E(\text{Var}(Y \epsilon \mid Y)) \\
  &= \text{Var}(Y E(\varepsilon \mid Y)) + E(Y^2 \text{Var}(\varepsilon \mid Y)) \\
  &= \text{Var}(Y E(\varepsilon)) + E(Y^2 \text{Var}(\varepsilon)) \\
  &= E(\varepsilon)^2 \text{Var}(Y) + E(Y^2) \text{Var}(\varepsilon) \\
  &= E(Y^2) \text{Var}(\varepsilon).
\end{align*}
```
```{=tex}
\begin{align*}
  \text{Var}(Z) &= \text{Var}(Y) + \text{Var}(Y \varepsilon) + 2 \text{Cov}(Y, Y \varepsilon) \\
  &= \text{Var}(Y) + E(Y^2) \text{Var}(\varepsilon).
\end{align*}
```
For some small Var$(\varepsilon)$, we will not have to worry about an extremely low case of $Z = 0$ for some $i$ which ensures variation onto $Y$ and positive $Z$.

```{r}
pps <- function(x, n, noise_sd) {
  noise = rnorm(length(x), 0, noise_sd)
  x_noisy = x * (1 + noise)
  pik = inclusionprobabilities(x_noisy, n)
  selected = UPbrewer(pik)
  return(list(pik = pik, sample = selected))
}
welp = pps(x = ce$FINCBTAX, n = 1000, noise_sd = 0.1)
```

### Two-stage Stratification (STSRS) 

```{r}
stratify <- function(stratum, nh) {
  pik = inclusionprobastrata(as.numeric(stratum), nh)
  
  sampled <- rep(0, length(stratum))
  for (s in levels(as.factor(stratum))) {
    indices <- which(stratum == s)
    selected <- UPbrewer(pik[indices])
    sampled[indices * selected] <- 1
  }
  
  return(list(pik = pik, sampled = sampled))
}
welp = stratify(stratum = ce$REGION, nh = c(150, 150, 500, 200))
```

### Two-stage Clustering (CL-SRS)

```{r}
clustering <- function(clusters, n, m) {
  selected_clusters <- sample(x = unique(clusters), size = n, replace = FALSE)
  
  sampled <- rep(0, length(clusters))
  for (c in selected_clusters) {
    indices <- which(clusters == c)
    selected <- sample(indices, size = m, replace = FALSE)
    sampled[selected] <- 1
  }
  
  clust_pik = data.frame(clust = clusters) %>% # Returns vector of the pik for a jth element
    group_by(clust) %>%
    summarize(pik = n / length(unique(clusters)) * m / n())
  
  pik_list = left_join(data.frame(clusters = clusters),
                       mutate(clust_pik, clusters = clust),
                       by = "clusters")
  
  return(list(pik = pik_list$pik, sampled = sampled))
}

hi = clustering(clusters = ce$CID, n = 25, m = 1)
sum(hi$sampled)
```

### Three-stage Clustering - Stratified (CL-ST-SRS)

```{r, message = FALSE}
three_stage_clust_strat <- function(clusters, stratum, n, sample_size) {
  selected_clusters <- sample(x = unique(clusters), size = n, replace = FALSE)
  clust_indices = which(clusters %in% selected_clusters)
  stratum_in_clust = paste0(clusters[clust_indices], "_", stratum[clust_indices])
  
  m = round(sample_size / length(unique(stratum_in_clust)), 0)
  sampled = threestage %>%
    filter(clusters %in% selected_clusters) %>%
    group_by(clusters, stratum) %>%
    sample_n(size = m, replace = FALSE) %>%
    ungroup()
  
  selected = rep(0, length(clusters))
  selected[sampled$index] <- 1
  
  stratum_pik = data.frame(clust = clusters, strat = stratum) %>%
    group_by(clust, strat) %>%
    summarize(pik = (n / length(unique(clusters))) * (m / n()),
              pi_I = (n / length(unique(clusters))),
              pi_II = (m / n()))
  
  pik_list = left_join(threestage, stratum_pik,
                       by = c("clusters" = "clust", "stratum" = "strat")) %>%
    mutate(pik = pik * sum(selected) / sum(pik)) # pik does not always equal n, so scale
  
  return(list(pik = pik_list$pik, sampled = selected, m = m))
}

hi = three_stage_clust_strat(clusters = ce$STATE, stratum = ce$POPSIZE,
                             n = 8, sample_size = 1000)
hi$m
```



## CE Simulation

```{r, message = FALSE, warning = FALSE}
n <- c(25, 50, 100, 500, 1000)
methods <- c("grouping", "pps", "stratify", "cluster", "threestage")

cases <- expand_grid(n, methods)

set.seed(51483464)
B = 5000

columns = c("case", "iteration", "DD", "PN", "HP", "PS1", "PS1q", "PS2", "PS2q", 
            "PS3", "WF", "LR")
storage = data.frame(matrix(nrow = 0, ncol = length(columns)))
colnames(storage) = columns

for (case in 1:nrow(cases)) {
  DD = PN = HP = PS1 = PS1q = PS2 = PS2q = PS3 = WF = LR = rep(NA, B)
  case_storage = data.frame(iteration = seq_len(B), DD, PN, HP, PS1, PS1q,
                            PS2, PS2q, PS3, WF, LR)
  
  for (b in 1:B) {

    sampling = NULL
    if (cases$methods[case] == "grouping") {
      sampling = grouping(x = ce$TOTEXPCQ, n = cases$n[case], strata_prob = c(0.1, 0.15, 0.25, 0.5))
    } 
    if (cases$methods[case] == "pps") {
      sampling = pps(x = ce$TOTEXPCQ, n = cases$n[case], noise_sd = 0.1)
    } 
    if (cases$methods[case] == "stratify") {
      sampling = stratify(stratum = ce$REGION, nh = c(150, 150, 500, 200))
    }
    if (cases$methods[case] == "cluster") {
      sampling = clustering(clusters = ce$CID, n = 25, m = cases$n[case] / 25)
    }
    if (cases$methods[case] == "threestage") {
      sampling = three_stage_clust_strat(clusters = ce$STATE, stratum = ce$POPSIZE,
                                         n = 7, sample_size = cases$n[case])
    }
    samp = ce[1:nrow(ce) * sampling$sample,] %>%
      mutate(wts = 1 / sampling$pik[1:nrow(ce) * sampling$sample])
    
    case_storage$HP[b] = HP_DC_test(data = samp, y = samp$FINCBTAX, x = samp$TOTEXPCQ, wts = samp$wts)
    case_storage$DD[b] = DD_WA_test(data = samp, y = samp$FINCBTAX, x = samp$TOTEXPCQ, wts = samp$wts)
    case_storage$PS1[b] = PS1_WA_test(data = samp, y = samp$FINCBTAX, x = samp$TOTEXPCQ, wts = samp$wts)
    case_storage$PS2[b] = PS2_WA_test(data = samp, y = samp$FINCBTAX, x = samp$TOTEXPCQ, wts = samp$wts)
    case_storage$PS3[b] = PS3_test(data = samp, y = samp$FINCBTAX, x = samp$TOTEXPCQ, wts = samp$wts)
    case_storage$WF[b] = WF_WA_test(data = samp, y = samp$FINCBTAX, x = samp$TOTEXPCQ, wts = samp$wts)
    case_storage$PN[b] = PN_test(data = samp, y = samp$FINCBTAX, x = samp$TOTEXPCQ, wts = samp$wts)
    case_storage$PS1q[b] = PS1q_WA_test(data = samp, y = samp$FINCBTAX, x = samp$TOTEXPCQ, wts = samp$wts)
    case_storage$PS2q[b] = PS2q_WA_test(data = samp, y = samp$FINCBTAX, x = samp$TOTEXPCQ, wts = samp$wts)
    case_storage$LR[b] = LR_test(data = samp, y = samp$FINCBTAX, x = samp$TOTEXPCQ, wts = samp$wts)
    
  }
  storage = rbind(storage, cbind(case, case_storage))
  print(case)
}
write.csv(storage, "ce_results.csv")
```

```{r}
test_results = read.csv("ce_results.csv")

test_reject = test_results %>%
  mutate(HP = case_when(HP <= 0.05 ~ 1, TRUE ~ 0),
         DD = case_when(DD <= 0.05 ~ 1, TRUE ~ 0),
         PS1 = case_when(PS1 <= 0.05 ~ 1, TRUE ~ 0),
         PS1q = case_when(PS1q <= 0.05 ~ 1, TRUE ~ 0),
         PS2 = case_when(PS2 <= 0.05 ~ 1, TRUE ~ 0),
         PS2q = case_when(PS2q <= 0.05 ~ 1, TRUE ~ 0),
         PS3 = case_when(PS3 <= 0.05 ~ 1, TRUE ~ 0),
         WF = case_when(WF <= 0.05 ~ 1, TRUE ~ 0),
         LR = case_when(LR <= 0.05 ~ 1, TRUE ~ 0),
         PN = case_when(PN <= 0.05 ~ 1, TRUE ~ 0)) %>%
  select(-iteration) %>%
  group_by(case) %>%
  summarize(across(everything(), mean)) %>%
  mutate(HP = format(round(HP * 100, 1), nsmall = 1),
         DD = format(round(DD * 100, 1), nsmall = 1),
         PS1 = format(round(PS1 * 100, 1), nsmall = 1),
         PS1q = format(round(PS1q * 100, 1), nsmall = 1),
         PS2 = format(round(PS2 * 100, 1), nsmall = 1),
         PS2q = format(round(PS2q * 100, 1), nsmall = 1),
         PS3 = format(round(PS3 * 100, 1), nsmall = 1),
         WF = format(round(WF * 100, 1), nsmall = 1),
         LR = format(round(LR * 100, 1), nsmall = 1),
         PN = format(round(PN * 100, 1), nsmall = 1))

test_reject_table = cbind(cases, test_reject) %>% select(-c(X, case))
test_reject_table

write.csv(test_reject_table, "ce_reject_table.csv")
```


















