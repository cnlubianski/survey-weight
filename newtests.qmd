---
title: "newtests"
format: html
editor: visual
---

# Proposed Tests

In addition to the listed survey weight diagnostic tests, I propose additional tests to determine survey weights' necessity in regression analysis.

```{r, message = FALSE, warning = FALSE}
if (!require(tidyverse)) install.packages("tidyverse"); library(tidyverse)
if (!require(rpms)) install.packages("rpms"); library(rpms)
if (!require(sampling)) install.packages("sampling"); library(sampling)
if (!require(survey)) install.packages("survey"); library(survey)
```

### Data Simulation - Study #1

```{r}
generate_data_study1 = function(N, sigma, alpha, delta) {
  X <- runif(N, 0, 1)
  u <- runif(N, 0, 1)
  epsilon <- rnorm(N, 0, sigma)
  
  Y <- 1 + X + epsilon
  w <- alpha * Y + 0.3 * X + delta[1] * u
  
  data = data.frame(y = Y, x = X, w, id = 1:N)
  return(data)
}

generate_sample_study1 = function(data, w, n) {
  pik = inclusionprobabilities(w, n)
  choosen = UPsampford(pik, max_iter = n)
  samp = data[1:N * choosen,]
  return(samp)
}

N <- 3000
n <- c(100, 200)
sigma <- c(0.1, 0.2)
alpha <- c(0, 0.2, 0.4, 0.6)
delta <- c(1, 1.5)

cases <- expand_grid(N, n, sigma, alpha, delta)
```


```{r}
library(microbenchmark)

generate_sample_tille = function(data, w, n) {
  pik = inclusionprobabilities(w, n)
  choosen = UPtille(pik)
  samp = data[1:N * choosen,]
  return(samp)
}

generate_sample_sampford = function(data, w, n) {
  pik = inclusionprobabilities(w, n)
  choosen = UPsampford(pik)
  samp = data[1:N * choosen,]
  return(samp)
}

generate_sample_brewer = function(data, w, n) {
  pik = inclusionprobabilities(w, n)
  choosen = UPbrewer(pik)
  samp = data[1:N * choosen,]
  return(samp)
}

generate_sample_midzuno = function(data, w, n) {
  pik = inclusionprobabilities(w, n)
  choosen = UPmidzuno(pik)
  samp = data[1:N * choosen,]
  return(samp)
}

set.seed(51483464)

pop = generate_data_study1(N = cases$N[32], sigma = cases$sigma[32],
                           alpha = cases$alpha[32], delta = cases$delta[32])

time_trials = microbenchmark("UPtille" = {b <- generate_sample_tille(data = pop,
                                                             w = pop$w,
                                                             n = cases$n[32])},
               #"UPsampford" = {b <- generate_sample_study1(data = pop,
                #                                             w = pop$w,
                 #                                            n = cases$n[32])},
               #"UPsampford_wo" = {b <- generate_sample_sampford(data = pop,
                #                                             w = pop$w,
                 #                                            n = cases$n[32])},
               "UPsampford_edited" = {b <- generate_sample_adapt_sampford(data = pop,
                                                             w = pop$w,
                                                             n = cases$n[32])},
               "UPbrewer" = {b <- generate_sample_brewer(data = pop,
                                                             w = pop$w,
                                                             n = cases$n[32])},
               "UPmidzuno" = {b <- generate_sample_midzuno(data = pop,
                                                             w = pop$w,
                                                             n = cases$n[32])},
               check = NULL, times = 1000)

print(time_trials)

write.csv(time_trials, "sampling_times.csv")

pik = inclusionprobabilities(pop$w, cases$n[32])
system.time(UPsampford(pik, max_iter = cases$n[32]))
system.time(UPsampford(pik))
system.time(UPtille(pik))
system.time(UPbrewer(pik))
system.time(UPmidzuno(pik))
system.time(adapt_UPsampford(pik))
```

```{r}
generate_sample_adapt_sampford = function(data, w, n) {
  pik = inclusionprobabilities(w, n)
  choosen = adapt_UPsampford(pik)
  samp = data[1:N * choosen,]
  return(samp)
}



adapt_UPsampford = function(pik, eps = 1e-06) 
{
    if (any(is.na(pik))) 
        stop("there are missing values in the pik vector")
    n = sum(pik)
    n = .as_int(n)
    list = pik > eps & pik < 1 - eps
    pikb = pik[list]
    n = sum(pikb)
    N = length(pikb)
    s = pik
    if (N < 1) 
        stop("the pik vector has all elements outside of the range [eps,1-eps]")
    else {
        sb = rep(2, N)
        y = pikb/(1 - pikb)/sum(pikb/(1 - pikb))
        step = 0
        while (sum(sb <= 1) != N & step <= max_iter) {
            sb = as.vector(rmultinom(1, 1, pikb/sum(pikb)) + 
                rmultinom(1, .as_int(n - 1), y))
            step = step + 1
        }
        if (sum(sb <= 1) == N) 
            s[list] = sb
        #else stop("Too many iterations. The algorithm was stopped.")
    }
    s
}

x = generate_sample_adapt_sampford(data = pop, w = pop$w, n = cases$n[32])
```


## Permutation Test - DC Version

```{r}
weight_perm_test <- function(y, x, w, B) {
  stat_stor = rep(NA, B)
  data = data.frame(x = x, y = y, w = w)
  # Permutating
  for (b in 1:B) {
    shuffled_w = sample(w)
    b_data = data.frame(y = y, x = x, w = shuffled_w, id = length(w))
    
    # Unweighted Regression
    unweighted = lm(y ~ x, data = b_data)
    beta_u = unweighted$coefficients[2] # faster to manually calculate beta_1
    #beta_u = sum((x - mean(x)) * (y - mean(y))) / sum((x - mean(x))^2)
    
    # Weighted Regression
    design = svydesign(id = ~1, weights = ~w, fpc = ~rep(N, nrow(b_data)),
                       data = b_data)
    weighted = svyglm(y ~ x, design = design)
    beta_w = weighted$coefficients[2]
    
    stat_stor[b] = beta_w - beta_u
  }
  
  # Estimating test statistic
  act_betau = lm(y ~ x, data = data)$coefficients[2]
  
  act_design = svydesign(id = ~1, weights = ~w, fpc = ~rep(N, nrow(data)),
                       data = data)
  act_betaw = svyglm(y ~ x, design = act_design)$coefficients[2]
  est_stat = act_betaw - act_betau
  
  # Calculating p-value
  dist = ecdf(stat_stor)
  p = dist(est_stat)
  pvalue = 2 * min(p, 1 - p)
  
  # return list for distribution and p-value
  return(pvalue)
}

pop = generate_data_study1(N = cases$N[32],
                                         sigma = cases$sigma[32],
                                         alpha = cases$alpha[32],
                                         delta = cases$delta[32])

actual = weight_perm_test(y = pop$y, x = pop$x, w = pop$w, B = 1000)

samp = generate_sample_study1(data = pop, w = pop$w, n = cases$n[32])
samp_test =  weight_perm_test(y = samp$y, x = samp$x, w = samp$w, B = 1000)
```

### Simulation

```{r, warning = FALSE}
# investigate warning
set.seed(51483464)
B = 1

# data storage set-up
columns = c("case", "iteration", "pvalue", "reject")
results = data.frame(matrix(nrow = 0, ncol = length(columns)))
colnames(results) = columns

# Iterate through cases, then through simulations
for (case in 1:nrow(cases)) {
  # Create case storage data frame for the entire case
  case_storage = data.frame(iteration = seq_len(B),
                       pvalue = rep(NA, B),
                       reject = rep(NA, B))
  
  # Run B simulations for a case
  for (b in 1:B) {
    pop_data = generate_data_study1(N = cases$N[case], # should be pop_data
                                       sigma = cases$sigma[case],
                                       alpha = cases$alpha[case],
                                       delta = cases$delta[case])
    sample_data = generate_sample_study1.1(data = pop_data, w = pop_data$w, n = cases$n[case])
    
    # something wrong with too large n
    case_storage$iteration[b] = b
    case_storage$pvalue[b] = weight_perm_test(y = sample_data$y, x = sample_data$x,
                               w = sample_data$w, B = 500)
    case_storage$reject[b] = as.numeric(case_storage$pvalue[b] <= 0.05)
  }
  results = rbind(results, cbind(case = rep(case, B), case_storage))
  print(case)
}

write.csv(results, "perm_results.csv")
results = read.csv("perm_results.csv")

aggre_results = results |>
  mutate(case = as.factor(case)) |>
  #select(case, reject) |>
  group_by(case) |>
  summarise(rejection_percent = mean(reject))

aggre_results
```




